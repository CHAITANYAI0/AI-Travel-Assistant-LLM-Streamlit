{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import warnings\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nest_asyncio.apply()\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "import qdrant_client\n",
    "import nest_asyncio\n",
    "import json\n",
    "import warnings\n",
    "import re\n",
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of URLs\n",
    "EU_tourism_URLs = ['https://www.planetware.com/tourist-attractions-/madrid-e-mad-mad.htm',\n",
    "                   'https://www.planetware.com/tourist-attractions-/barcelona-e-cat-bar.htm',\n",
    "                   'https://www.planetware.com/tourist-attractions-/milan-i-lo-m.htm',\n",
    "                   'https://www.planetware.com/tourist-attractions-/monaco-mc-mc-mon.htm',\n",
    "                   'https://www.trawell.in/blog/stunning-places-to-visit-in-berlin',\n",
    "                   'https://www.trawell.in/blog/popular-tourist-places-in-london',\n",
    "                   'https://www.trawell.in/blog/most-beautiful-places-to-visit-in-paris',\n",
    "                   'https://www.planetware.com/tourist-attractions-/prague-cz-pr-p.htm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini AI vector Embedding Model\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Gemini AI model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", gemini_api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping loader\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def webscrapper(urls: list):\n",
    "\n",
    "\n",
    "    # load URLs\n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "\n",
    "\n",
    "    # Apply BS4 transformer\n",
    "    bs_transformer = BeautifulSoupTransformer()\n",
    "    docs_transformed = bs_transformer.transform_documents(\n",
    "            # Extract content from given tags\n",
    "            docs, tags_to_extract=[\"p\", \"h2\", \"span\"]\n",
    "        )\n",
    "   \n",
    "    # Perform Tokenization using Text Splitter\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0)\n",
    "    print('\\n>Splitting documents into chunks')\n",
    "    chunks = splitter.split_documents(docs_transformed)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Qdrant Collection to store vector embeddings\n",
    "def qdrant_collection(text_chunks, embedding_model, collection_name):\n",
    "    print(\"> Creating QdrantDB connection\")\n",
    "    # Create a Qdrant Client\n",
    "    client = qdrant_client.QdrantClient(\n",
    "        qdrant_url,\n",
    "        api_key=qdrant_api_key\n",
    "    )\n",
    "\n",
    "    print(\">\\nQdrant connection established.\")\n",
    "    # Create a collection\n",
    "    vectors_config = qdrant_client.http.models.VectorParams(\n",
    "        size=768, # Define fixed size of chunk to store\n",
    "        distance=qdrant_client.http.models.Distance.COSINE\n",
    "    )\n",
    "   \n",
    "    # Let's create collection (Using recreate so we can run this multiple times)\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=vectors_config\n",
    "    )\n",
    "   \n",
    "    # Save in Qdrant DB\n",
    "    qdrant = Qdrant.from_documents(\n",
    "        text_chunks,\n",
    "        embedding_model,\n",
    "        url=qdrant_url,\n",
    "        api_key=qdrant_api_key,\n",
    "        prefer_grpc=True,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(\"> Chunk of text saved in Qdrant DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEB SCRAPPING AND VECTOR EMBEDDING PROCESS BEGINS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727807410.509360 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807412.753926 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807414.418227 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807415.683293 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807416.982601 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807421.287915 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807425.900262 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1727807429.612950 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">Splitting documents into chunks\n",
      "> Creating QdrantDB connection\n",
      ">\n",
      "Qdrant connection established.\n",
      "> Chunk of text saved in Qdrant DB\n"
     ]
    }
   ],
   "source": [
    "print(\"WEB SCRAPPING AND VECTOR EMBEDDING PROCESS BEGINS\")\n",
    "docs = webscrapper(EU_tourism_URLs)\n",
    "qdrant_collection(docs, embeddings, collection_name='europe-tour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import textwrap\n",
    "import qdrant_client\n",
    "import streamlit as st\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "    You are helpful tourism search engine. Give information about that places by given query. Always answer as helpful and as relevant\n",
    "    as possible. While being informative. Keep answer length about 100-200 words. \n",
    "    If you don't know the answer to a question, please don't share false information.    \n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "Query: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(sys_prompt,instruction):\n",
    "    prompt_template =  sys_prompt + instruction\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector store in action\n",
    "def get_vector_store():\n",
    "    # Connect to the QdrantDB Cloud\n",
    "    client = qdrant_client.QdrantClient(\n",
    "        qdrant_url,\n",
    "        api_key=qdrant_api_key\n",
    "    )\n",
    "   \n",
    "    # Define Embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "   \n",
    "    # Vector store for Retrieval\n",
    "    vector_store = Qdrant(\n",
    "        client=client,\n",
    "        collection_name='europe-tour',\n",
    "        embeddings=embeddings\n",
    "    )\n",
    "   \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    # Get parsed answer\n",
    "    text = wrap_text_preserve_newlines(llm_response['result'])\n",
    "   \n",
    "    # Uncouple metadata and return it\n",
    "    sources=[]\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        sources.append(source.metadata['source'])\n",
    "    return text, list(set(sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 14:34:54.281 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.282 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.308 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/chaitanya/Documents/ML/github/AI-Travel-Assistant/env/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-01 14:34:54.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.471 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.476 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.478 Session state does not function when running a script without `streamlit run`\n",
      "2024-10-01 14:34:54.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-01 14:34:54.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define vector store\n",
    "    vector_store = get_vector_store()\n",
    "   \n",
    "    # Using Gemini-Pro\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", gemini_api_key=gemini_api_key,\n",
    "                                 temperature=0.3,\n",
    "                                 max_tokens=1024,\n",
    "                                 convert_system_message_to_human=True)\n",
    "\n",
    "\n",
    "    # Generate Prompt Template\n",
    "    prompt_template = get_prompt(instruction, sys_prompt)\n",
    "    QA_prompt = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "   \n",
    "    # Create Retrieval Chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_store.as_retriever( search_kwargs={\"k\":3}),\n",
    "        return_source_documents=True, # Get source\n",
    "        chain_type_kwargs={\"prompt\":QA_prompt}\n",
    "    )\n",
    "   \n",
    "    # Set Streamlit UI\n",
    "    st.set_page_config(page_title=\"AI Tour Assistant\")\n",
    "   \n",
    "   \n",
    "    st.markdown(\"# AI Europe-Tour Assistant\")\n",
    "   \n",
    "    image = Image.open('europe_banner.jpg')\n",
    "    st.image(image, caption='by Karan Shingde', use_column_width=True)\n",
    "   \n",
    "    st.header(\"Tell us about your dream Europe destination?\")\n",
    "   \n",
    "    # Create text box so user can write query\n",
    "    user_question = st.text_input(\"What place would you love to explore?\")\n",
    "    if user_question:\n",
    "        llm_res = qa_chain.invoke(user_question) # Generate response\n",
    "        response, sources = process_llm_response(llm_res) # Trim it using Output Parser\n",
    "        st.write()\n",
    "        st.write()\n",
    "        st.markdown(\"### Based on your search:\")\n",
    "        st.write(f\"{response}\")\n",
    "        st.markdown(\"##### Source: \")\n",
    "        for source in sources: # Display source URLs\n",
    "            st.markdown(f\"[{source}]({source})\", unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727808989.811103 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-qdrant in ./env/lib/python3.12/site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1.52 in ./env/lib/python3.12/site-packages (from langchain-qdrant) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./env/lib/python3.12/site-packages (from langchain-qdrant) (2.9.2)\n",
      "Requirement already satisfied: qdrant-client<2.0.0,>=1.10.1 in ./env/lib/python3.12/site-packages (from langchain-qdrant) (1.11.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1.52->langchain-qdrant) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1.52->langchain-qdrant) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./env/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1.52->langchain-qdrant) (0.1.129)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1.52->langchain-qdrant) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1.52->langchain-qdrant) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1.52->langchain-qdrant) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-qdrant) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-qdrant) (2.23.4)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in ./env/lib/python3.12/site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.66.2)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in ./env/lib/python3.12/site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.66.2)\n",
      "Requirement already satisfied: httpx>=0.20.0 in ./env/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (0.27.2)\n",
      "Requirement already satisfied: numpy>=1.26 in ./env/lib/python3.12/site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in ./env/lib/python3.12/site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./env/lib/python3.12/site-packages (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (2.2.3)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in ./env/lib/python3.12/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (5.28.2)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.12/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (75.1.0)\n",
      "Requirement already satisfied: anyio in ./env/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.0.6)\n",
      "Requirement already satisfied: idna in ./env/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (3.10)\n",
      "Requirement already satisfied: sniffio in ./env/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in ./env/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (4.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.52->langchain-qdrant) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.52->langchain-qdrant) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.52->langchain-qdrant) (2.32.3)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in ./env/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in ./env/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.1.52->langchain-qdrant) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727809116.970857 2388306 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-qdrant\n",
      "Version: 0.1.4\n",
      "Summary: An integration package connecting Qdrant and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/chaitanya/Documents/ML/github/AI-Travel-Assistant/env/lib/python3.12/site-packages\n",
      "Requires: langchain-core, pydantic, qdrant-client\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain-qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import Qdrant\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
